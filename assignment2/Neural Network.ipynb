{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1, -2, 3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "# check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- Loss: 2.084752, Train accuracy: 0.247222, val accuracy: 0.252000\n",
      "Epoch 1 -- Loss: 2.032992, Train accuracy: 0.450333, val accuracy: 0.429000\n",
      "Epoch 2 -- Loss: 1.873418, Train accuracy: 0.518889, val accuracy: 0.505000\n",
      "Epoch 3 -- Loss: 1.762300, Train accuracy: 0.554889, val accuracy: 0.554000\n",
      "Epoch 4 -- Loss: 1.781435, Train accuracy: 0.547444, val accuracy: 0.547000\n",
      "Epoch 5 -- Loss: 1.765458, Train accuracy: 0.562889, val accuracy: 0.567000\n",
      "Epoch 6 -- Loss: 1.639317, Train accuracy: 0.568556, val accuracy: 0.565000\n",
      "Epoch 7 -- Loss: 1.785481, Train accuracy: 0.582111, val accuracy: 0.583000\n",
      "Epoch 8 -- Loss: 1.691486, Train accuracy: 0.590778, val accuracy: 0.594000\n",
      "Epoch 9 -- Loss: 1.952903, Train accuracy: 0.587333, val accuracy: 0.551000\n",
      "Epoch 10 -- Loss: 1.621183, Train accuracy: 0.564667, val accuracy: 0.568000\n",
      "Epoch 11 -- Loss: 1.859847, Train accuracy: 0.579111, val accuracy: 0.580000\n",
      "Epoch 12 -- Loss: 1.656692, Train accuracy: 0.595222, val accuracy: 0.582000\n",
      "Epoch 13 -- Loss: 1.808040, Train accuracy: 0.589889, val accuracy: 0.563000\n",
      "Epoch 14 -- Loss: 1.734058, Train accuracy: 0.601444, val accuracy: 0.611000\n",
      "Epoch 15 -- Loss: 1.432330, Train accuracy: 0.618778, val accuracy: 0.598000\n",
      "Epoch 16 -- Loss: 1.930720, Train accuracy: 0.548556, val accuracy: 0.545000\n",
      "Epoch 17 -- Loss: 1.892465, Train accuracy: 0.507333, val accuracy: 0.495000\n",
      "Epoch 18 -- Loss: 2.024002, Train accuracy: 0.540333, val accuracy: 0.545000\n",
      "Epoch 19 -- Loss: 1.831031, Train accuracy: 0.574444, val accuracy: 0.568000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down and train and val accuracy go up for every epoch\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28ba64c5160>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- Loss: 2.090616, Train accuracy: 0.275000, val accuracy: 0.286000\n",
      "Epoch 1 -- Loss: 1.907026, Train accuracy: 0.400889, val accuracy: 0.440000\n",
      "Epoch 2 -- Loss: 1.850348, Train accuracy: 0.495778, val accuracy: 0.508000\n",
      "Epoch 3 -- Loss: 1.811390, Train accuracy: 0.521333, val accuracy: 0.528000\n",
      "Epoch 4 -- Loss: 1.670871, Train accuracy: 0.523222, val accuracy: 0.522000\n",
      "Epoch 5 -- Loss: 2.007474, Train accuracy: 0.596778, val accuracy: 0.586000\n",
      "Epoch 6 -- Loss: 1.690956, Train accuracy: 0.593778, val accuracy: 0.596000\n",
      "Epoch 7 -- Loss: 2.312451, Train accuracy: 0.602889, val accuracy: 0.603000\n",
      "Epoch 8 -- Loss: 1.980329, Train accuracy: 0.587778, val accuracy: 0.597000\n",
      "Epoch 9 -- Loss: 2.059136, Train accuracy: 0.590111, val accuracy: 0.582000\n",
      "Epoch 10 -- Loss: 1.762179, Train accuracy: 0.536333, val accuracy: 0.536000\n",
      "Epoch 11 -- Loss: 1.886594, Train accuracy: 0.606000, val accuracy: 0.602000\n",
      "Epoch 12 -- Loss: 1.663816, Train accuracy: 0.596778, val accuracy: 0.608000\n",
      "Epoch 13 -- Loss: 2.202530, Train accuracy: 0.571444, val accuracy: 0.585000\n",
      "Epoch 14 -- Loss: 2.111489, Train accuracy: 0.601778, val accuracy: 0.596000\n",
      "Epoch 15 -- Loss: 2.137902, Train accuracy: 0.627111, val accuracy: 0.609000\n",
      "Epoch 16 -- Loss: 1.864367, Train accuracy: 0.614444, val accuracy: 0.614000\n",
      "Epoch 17 -- Loss: 1.731207, Train accuracy: 0.610556, val accuracy: 0.616000\n",
      "Epoch 18 -- Loss: 1.486332, Train accuracy: 0.614556, val accuracy: 0.596000\n",
      "Epoch 19 -- Loss: 1.750731, Train accuracy: 0.613222, val accuracy: 0.596000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99, learning_rate=1e-1)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- Loss: 2.072176, Train accuracy: 0.303111, val accuracy: 0.299000\n",
      "Epoch 1 -- Loss: 1.334082, Train accuracy: 0.521000, val accuracy: 0.515000\n",
      "Epoch 2 -- Loss: 1.112879, Train accuracy: 0.618778, val accuracy: 0.630000\n",
      "Epoch 3 -- Loss: 1.371165, Train accuracy: 0.683778, val accuracy: 0.667000\n",
      "Epoch 4 -- Loss: 1.273046, Train accuracy: 0.692667, val accuracy: 0.682000\n",
      "Epoch 5 -- Loss: 0.889134, Train accuracy: 0.726889, val accuracy: 0.706000\n",
      "Epoch 6 -- Loss: 1.470488, Train accuracy: 0.728000, val accuracy: 0.704000\n",
      "Epoch 7 -- Loss: 1.040038, Train accuracy: 0.750111, val accuracy: 0.690000\n",
      "Epoch 8 -- Loss: 1.056243, Train accuracy: 0.735333, val accuracy: 0.679000\n",
      "Epoch 9 -- Loss: 1.722421, Train accuracy: 0.752444, val accuracy: 0.713000\n",
      "Epoch 10 -- Loss: 1.200305, Train accuracy: 0.736778, val accuracy: 0.686000\n",
      "Epoch 11 -- Loss: 1.107190, Train accuracy: 0.790556, val accuracy: 0.709000\n",
      "Epoch 12 -- Loss: 1.110588, Train accuracy: 0.749667, val accuracy: 0.695000\n",
      "Epoch 13 -- Loss: 0.922559, Train accuracy: 0.795444, val accuracy: 0.723000\n",
      "Epoch 14 -- Loss: 0.754085, Train accuracy: 0.760222, val accuracy: 0.677000\n",
      "Epoch 15 -- Loss: 1.094497, Train accuracy: 0.796111, val accuracy: 0.721000\n",
      "Epoch 16 -- Loss: 1.411420, Train accuracy: 0.804444, val accuracy: 0.713000\n",
      "Epoch 17 -- Loss: 1.342219, Train accuracy: 0.823444, val accuracy: 0.733000\n",
      "Epoch 18 -- Loss: 0.730275, Train accuracy: 0.832778, val accuracy: 0.752000\n",
      "Epoch 19 -- Loss: 0.642245, Train accuracy: 0.829000, val accuracy: 0.729000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- Loss: 2.326562, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 1 -- Loss: 2.320516, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 2 -- Loss: 2.298805, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 3 -- Loss: 2.312076, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 4 -- Loss: 2.254935, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Epoch 5 -- Loss: 2.254170, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 6 -- Loss: 1.967769, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 7 -- Loss: 2.360984, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 8 -- Loss: 1.774991, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 9 -- Loss: 1.840185, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 10 -- Loss: 2.649836, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 11 -- Loss: 1.686522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 12 -- Loss: 1.859028, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 13 -- Loss: 1.784324, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 14 -- Loss: 1.330489, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 15 -- Loss: 1.590655, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 16 -- Loss: 1.795437, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 17 -- Loss: 1.835210, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Epoch 18 -- Loss: 1.581600, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 19 -- Loss: 2.073769, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 20 -- Loss: 1.531695, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Epoch 21 -- Loss: 1.727000, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Epoch 22 -- Loss: 1.783540, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 23 -- Loss: 1.939821, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Epoch 24 -- Loss: 1.786638, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 25 -- Loss: 1.934912, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 26 -- Loss: 1.356259, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 27 -- Loss: 2.566744, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Epoch 28 -- Loss: 1.385665, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 29 -- Loss: 1.003550, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Epoch 30 -- Loss: 2.646629, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 31 -- Loss: 1.329929, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 32 -- Loss: 1.275249, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 33 -- Loss: 0.982827, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 34 -- Loss: 1.048236, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 35 -- Loss: 1.514702, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 36 -- Loss: 2.062605, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Epoch 37 -- Loss: 1.541595, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 38 -- Loss: 1.894370, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Epoch 39 -- Loss: 1.627926, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Epoch 40 -- Loss: 1.388099, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 41 -- Loss: 1.766504, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 42 -- Loss: 2.210618, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 43 -- Loss: 1.584733, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 44 -- Loss: 1.684035, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 45 -- Loss: 1.496463, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 46 -- Loss: 1.426912, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 47 -- Loss: 1.540991, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 48 -- Loss: 2.257532, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 49 -- Loss: 2.102660, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 50 -- Loss: 1.718963, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Epoch 51 -- Loss: 1.482464, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 52 -- Loss: 1.619929, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 53 -- Loss: 1.674000, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 54 -- Loss: 1.673999, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 55 -- Loss: 1.826838, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 56 -- Loss: 1.825361, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Epoch 57 -- Loss: 1.072189, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Epoch 58 -- Loss: 1.501895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 59 -- Loss: 1.610071, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 60 -- Loss: 0.894665, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 61 -- Loss: 1.646274, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 62 -- Loss: 0.923096, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 63 -- Loss: 1.334055, Train accuracy: 0.866667, val accuracy: 0.133333\n",
      "Epoch 64 -- Loss: 1.533929, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 65 -- Loss: 1.962119, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 66 -- Loss: 1.457128, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 67 -- Loss: 0.952321, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 68 -- Loss: 1.199275, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 69 -- Loss: 1.156545, Train accuracy: 0.933333, val accuracy: 0.133333\n",
      "Epoch 70 -- Loss: 1.043624, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 71 -- Loss: 1.014025, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 72 -- Loss: 1.607857, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 73 -- Loss: 1.074902, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 74 -- Loss: 1.442023, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 75 -- Loss: 1.646868, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 76 -- Loss: 1.252729, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Epoch 77 -- Loss: 1.311782, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 78 -- Loss: 1.783173, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 79 -- Loss: 1.271101, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 80 -- Loss: 1.401481, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 81 -- Loss: 1.370778, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Epoch 82 -- Loss: 1.221364, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 83 -- Loss: 1.254792, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 84 -- Loss: 1.702904, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 85 -- Loss: 1.377662, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Epoch 86 -- Loss: 1.952354, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Epoch 87 -- Loss: 1.417936, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 88 -- Loss: 1.863688, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 89 -- Loss: 1.560516, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 90 -- Loss: 1.323894, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 91 -- Loss: 1.794228, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 92 -- Loss: 1.439915, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 93 -- Loss: 1.311506, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 94 -- Loss: 1.141533, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 95 -- Loss: 1.559370, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 96 -- Loss: 1.682727, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 97 -- Loss: 1.342959, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 98 -- Loss: 1.336648, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 99 -- Loss: 1.902690, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=100, batch_size=3)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- Loss: 2.337101, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Epoch 1 -- Loss: 2.359802, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 2 -- Loss: 2.282119, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 3 -- Loss: 2.280018, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 4 -- Loss: 1.700171, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 5 -- Loss: 1.379624, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 6 -- Loss: 1.137110, Train accuracy: 0.600000, val accuracy: 0.133333\n",
      "Epoch 7 -- Loss: 1.982313, Train accuracy: 0.600000, val accuracy: 0.133333\n",
      "Epoch 8 -- Loss: 0.585998, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 9 -- Loss: 1.624545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 10 -- Loss: 0.874815, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 11 -- Loss: 0.950598, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Epoch 12 -- Loss: 1.232490, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 13 -- Loss: 0.579112, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 14 -- Loss: 0.802243, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Epoch 15 -- Loss: 0.637624, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 16 -- Loss: 0.516678, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 17 -- Loss: 0.316729, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 18 -- Loss: 0.109947, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 19 -- Loss: 0.518860, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 150, reg = 1e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=3)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- Loss: 2.137341, Train accuracy: 0.429222, val accuracy: 0.453000\n",
      "Epoch 1 -- Loss: 1.619867, Train accuracy: 0.584444, val accuracy: 0.575000\n",
      "Epoch 2 -- Loss: 1.660584, Train accuracy: 0.648667, val accuracy: 0.626000\n",
      "Epoch 3 -- Loss: 1.218745, Train accuracy: 0.696556, val accuracy: 0.673000\n",
      "Epoch 4 -- Loss: 1.377792, Train accuracy: 0.705556, val accuracy: 0.686000\n",
      "Epoch 5 -- Loss: 1.357399, Train accuracy: 0.724778, val accuracy: 0.706000\n",
      "Epoch 6 -- Loss: 1.253490, Train accuracy: 0.750778, val accuracy: 0.721000\n",
      "Epoch 7 -- Loss: 0.978884, Train accuracy: 0.762111, val accuracy: 0.722000\n",
      "Epoch 8 -- Loss: 1.234904, Train accuracy: 0.777444, val accuracy: 0.731000\n",
      "Epoch 9 -- Loss: 1.215875, Train accuracy: 0.784556, val accuracy: 0.720000\n",
      "Epoch 10 -- Loss: 1.204675, Train accuracy: 0.799111, val accuracy: 0.736000\n",
      "Epoch 11 -- Loss: 1.034411, Train accuracy: 0.788444, val accuracy: 0.727000\n",
      "Epoch 12 -- Loss: 1.339513, Train accuracy: 0.790667, val accuracy: 0.731000\n",
      "Epoch 13 -- Loss: 0.831729, Train accuracy: 0.795889, val accuracy: 0.727000\n",
      "Epoch 14 -- Loss: 0.850660, Train accuracy: 0.811111, val accuracy: 0.737000\n",
      "Epoch 15 -- Loss: 0.898303, Train accuracy: 0.818000, val accuracy: 0.747000\n",
      "Epoch 16 -- Loss: 1.029277, Train accuracy: 0.816778, val accuracy: 0.743000\n",
      "Epoch 17 -- Loss: 0.836568, Train accuracy: 0.813556, val accuracy: 0.729000\n",
      "Epoch 18 -- Loss: 0.966352, Train accuracy: 0.846556, val accuracy: 0.747000\n",
      "Epoch 19 -- Loss: 0.664379, Train accuracy: 0.851000, val accuracy: 0.752000\n",
      "Epoch 20 -- Loss: 1.086307, Train accuracy: 0.850333, val accuracy: 0.760000\n",
      "Epoch 21 -- Loss: 0.953360, Train accuracy: 0.847556, val accuracy: 0.748000\n",
      "Epoch 22 -- Loss: 0.587757, Train accuracy: 0.843556, val accuracy: 0.756000\n",
      "Epoch 23 -- Loss: 0.796306, Train accuracy: 0.867444, val accuracy: 0.759000\n",
      "Epoch 24 -- Loss: 0.797269, Train accuracy: 0.868667, val accuracy: 0.753000\n",
      "Epoch 25 -- Loss: 0.869483, Train accuracy: 0.867667, val accuracy: 0.755000\n",
      "Epoch 26 -- Loss: 0.798534, Train accuracy: 0.871444, val accuracy: 0.767000\n",
      "Epoch 27 -- Loss: 0.846763, Train accuracy: 0.881333, val accuracy: 0.765000\n",
      "Epoch 28 -- Loss: 0.839954, Train accuracy: 0.866444, val accuracy: 0.751000\n",
      "Epoch 29 -- Loss: 0.691786, Train accuracy: 0.874333, val accuracy: 0.752000\n",
      "Epoch 30 -- Loss: 0.771196, Train accuracy: 0.879444, val accuracy: 0.763000\n",
      "Epoch 31 -- Loss: 1.028665, Train accuracy: 0.877778, val accuracy: 0.745000\n",
      "Epoch 32 -- Loss: 0.933467, Train accuracy: 0.879000, val accuracy: 0.760000\n",
      "Epoch 33 -- Loss: 0.843848, Train accuracy: 0.882667, val accuracy: 0.765000\n",
      "Epoch 34 -- Loss: 0.801745, Train accuracy: 0.886444, val accuracy: 0.760000\n",
      "Epoch 35 -- Loss: 0.868112, Train accuracy: 0.888444, val accuracy: 0.762000\n",
      "Epoch 36 -- Loss: 0.878028, Train accuracy: 0.878222, val accuracy: 0.753000\n",
      "Epoch 37 -- Loss: 0.922995, Train accuracy: 0.899222, val accuracy: 0.766000\n",
      "Epoch 38 -- Loss: 0.715749, Train accuracy: 0.892333, val accuracy: 0.764000\n",
      "Epoch 39 -- Loss: 0.766454, Train accuracy: 0.895556, val accuracy: 0.767000\n",
      "Epoch 40 -- Loss: 0.673324, Train accuracy: 0.892333, val accuracy: 0.765000\n",
      "Epoch 41 -- Loss: 0.766868, Train accuracy: 0.883778, val accuracy: 0.757000\n",
      "Epoch 42 -- Loss: 0.633083, Train accuracy: 0.893222, val accuracy: 0.775000\n",
      "Epoch 43 -- Loss: 0.771465, Train accuracy: 0.899889, val accuracy: 0.758000\n",
      "Epoch 44 -- Loss: 0.919432, Train accuracy: 0.896889, val accuracy: 0.768000\n",
      "Epoch 45 -- Loss: 0.724833, Train accuracy: 0.891556, val accuracy: 0.764000\n",
      "Epoch 46 -- Loss: 0.800572, Train accuracy: 0.909667, val accuracy: 0.769000\n",
      "Epoch 47 -- Loss: 0.887985, Train accuracy: 0.894778, val accuracy: 0.769000\n",
      "Epoch 48 -- Loss: 0.551918, Train accuracy: 0.888444, val accuracy: 0.758000\n",
      "Epoch 49 -- Loss: 0.782486, Train accuracy: 0.903333, val accuracy: 0.766000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "model_hyper_params = {'reg': 1e-3, 'hidden_layer_size': 128}\n",
    "trainer_hyper_params = {'num_epochs': 50, 'batch_size': 50, 'learning_rate': 1e-2, 'learning_rate_decay': 0.999}\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, **model_hyper_params)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), **trainer_hyper_params)\n",
    "    \n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "best_classifier = model\n",
    "# print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.746000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
